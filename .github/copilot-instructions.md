# Copilot Instructions for ORION Business Rules Engine

## Project Overview

ORION is a native C++ DMN™ Level 1 rule engine focused on decision tables with an emphasis on performance, correctness, and clean integration. The project prioritizes **generic solutions only** - no hardcoded values, domain-specific assumptions, or test-specific code patterns.

**IMPORTANT: This is a 100% AI-Generated Project.**
All source code changes must be generated by an AI agent based on a detailed task prompt. Manual edits are permitted only for documentation and configuration.

## Core Operating Principle

**PROCESS COMPLIANCE > SPEED**

Following the defined process correctly is MORE IMPORTANT than completing work quickly. Process checkpoints exist to ensure quality, user alignment, and learning - they are not optional optimizations.

### Mandatory Process Gates (HARD STOPS)

> ⚠️ If you think "I'll skip this to save time" - STOP. That checkpoint exists for a reason.

1. **User Feedback Checkpoints** 
   - When a task says "Ask for feedback" → STOP and wait for user response
   - Never assume user approval or skip feedback requests
   
2. **Evidence-Based Statements**
   - Use tools (`read_file`, `grep_search`) BEFORE stating facts
   - Never speculate with "probably", "likely", "seems"
   
3. **Sequential Verification**
   - Build → Verify → Test → Verify (never batch unless instructed)
   - Each step must pass before proceeding
   
4. **Task Retrospective**
   - Step 1: ASK user "What worked? What was unclear?" (mandatory)
   - Step 2: Analyze execution (only after user feedback)
   
5. **Simple Commands Only**
   - No pipes, redirection, or chaining (see Command Rules below)
   - One command → verify → next command

6. **Follow Instruction Files**
   - When working on build, test, or quality tasks, READ the applicable instruction file COMPLETELY
   - Instructions in `./instructions/*.md` are authoritative for those workflows
   - Never assume - always verify against the instruction files

7. **Two-Phase Task Workflow**
   - Phase 1 (Create Task): User requests task creation → Agent creates task file → STOP
   - Phase 2 (Execute Task): User says "execute" → Agent creates branch → implements → tests → retrospective
   - NEVER auto-execute after creating task file
   - See [Development Workflow](#development-workflow) for complete process

## Architecture Overview

### Core Components (`src/bre/`)
- **`engine.hpp/cpp`** - Main `BusinessRulesEngine` with stateful model management
- **`dmn_parser.hpp/cpp`** - DMN XML parsing (rapidxml)
- **`feel_evaluator.hpp/cpp`** - FEEL expression evaluation
- **`dmn_model.hpp`** - Data structures: `DecisionTable`, `LiteralDecision`
- **`hit_policy.hpp/cpp`** - FIRST, UNIQUE, COLLECT with aggregations
- **`bkm_manager.hpp/cpp`** - Business Knowledge Model management

### Key Usage Pattern

```cpp
// ✅ CORRECT: Load once, evaluate many (9-45 μs/eval)
orion::bre::BusinessRulesEngine engine;
auto result = engine.load_dmn_model(dmn_xml);  // One-time: 100-200μs
if (!result) {
    std::cerr << "Error: " << result.error() << std::endl;
    return 1;
}

for (auto& request : requests) {
    std::string result = engine.evaluate(request_json);  // 9-45μs each
}

// ❌ WRONG: Re-parse every time (100-150 μs/eval - 10x slower!)
for (auto& request : requests) {
    std::string result = evaluate(dmn_xml, request_json);  // DEPRECATED
}
```

**Performance:** 22,000-110,000 evaluations/second with cached models

## Quick Start Resources

**Build & Test:**
- [Build Instructions](./instructions/build.md) - CMake, vcpkg, compilation
- [Unit Tests](./instructions/run_unit_tests.md) - Boost Test execution
- [TCK Tests](./instructions/run_tck_tests.md) - DMN compliance validation
- [Performance Tests](./instructions/run_perf_tests.md) - Benchmarking
- [Adaptive CI Loop](./instructions/adaptive_ci_loop.md) - Intelligent testing for refactoring

**Development:**
- [DMN Feature Template](./prompts/add_dmn_feature.md) - Implement new FEEL features
- [Code Quality Template](./prompts/improve_quality.md) - Iterative quality improvements
- [Performance Template](./prompts/improve_perf.md) - Profile and optimize
- [Bug Fix Template](./prompts/fix_bug.md) - Debug and fix issues

**Standards:**
- [CODING_STANDARDS.md](../CODING_STANDARDS.md) - Naming, error handling, memory management
- [Code Review Checklist](./instructions/code_review_checklist.md) - Quality gates for all changes
- DMN 1.5 Spec: `docs/formal-24-01-01.txt` - Official OMG specification

## Development Workflow

### Two-Phase Task Execution (MANDATORY)

> ⚠️ **CRITICAL PROCESS GATE**: This is a TWO-PHASE workflow with a HARD STOP between phases.

#### Phase 1: Task Creation & Refinement (Planning)

**When the user requests "create a task file":**

User should provide:
- Goal/objective of the task
- Which template to use (from `.github/prompts/`): `add_dmn_feature`, `improve_quality`, `improve_perf`, `fix_bug`
- Any specific requirements or constraints

**Agent steps:**

1. **Ask clarifying questions ONLY if needed** to resolve ambiguities or gather missing details
   
   When asking questions, use multiple-choice format:
   ```
   Question: [What needs clarification?]
   
   A) [Option A] - Pros: [key benefits] | Cons: [key tradeoffs]
   B) [Option B] - Pros: [key benefits] | Cons: [key tradeoffs]  
   C) [Option C] - Pros: [key benefits] | Cons: [key tradeoffs]
   
   Recommendation: [Letter] because [brief reason]
   ```
   
   **User can respond:**
   - Choose an option: "A", "B", or "C"
   - Modify: "A, but [modification]"
   - Combine: "A and B"
   - Reject all: "None of the above, instead [alternative]"

2. **Create task file** in `.github/tasks/<ISSUE_NUMBER>_<snake_case_title>.md`
   - Use appropriate template from `.github/prompts/`
   - Fill in all required YAML frontmatter fields
   - Ensure success criteria are measurable

3. **Wait for user refinement** 
   - User may review and approve as-is
   - User may edit task file directly
   - User may ask you to refine specific sections

4. ⚠️ **STOP - DO NOT PROCEED TO IMPLEMENTATION** ⚠️

**DO NOT in Phase 1:**
- ❌ Create feature branch (Phase 2 only)
- ❌ Start implementation (Phase 2 only)
- ❌ Make code changes (Phase 2 only)
- ❌ Run build or tests (Phase 2 only)

#### Phase 2: Task Execution (Implementation)

**Trigger:** User explicitly says "execute" (or "implement", "run task", etc.)

**Mandatory steps in order:**

1. ✅ **Create feature branch** (NEVER work on main)
   ```bash
   git checkout -b feature/<task-name>
   ```
   
2. ✅ **Implement changes** following task file instructions
   - Follow applicable template from `.github/prompts/`
   - Reference instruction files for build/test workflows
   - Use evidence-based reasoning (read files before stating facts)

3. ✅ **Verify with build + tests**
   - Follow [Build Instructions](./instructions/build.md)
   - Follow [Test Instructions](./instructions/run_unit_tests.md)
   - No shortcuts - each step must pass

4. ✅ **Fill retrospective** in task file (MANDATORY before completion)
   - Step 1: ASK user "What worked? What was unclear?" 
   - Step 2: After user feedback, analyze execution
   - Document: what worked, what was problematic, blockers, actual effort
   
5. ✅ **Commit** with reference to task file in message
   ```bash
   git commit -m "feat: <description>
   
   Task: .github/tasks/<task-file>.md"
   ```

**Process Validation Checkpoints:**
- ✅ Did user say "create task"? → Execute Phase 1 only, then STOP
- ✅ Did user say "execute"? → Verify task file exists, then execute Phase 2
- ✅ Is retrospective filled before marking complete? → Mandatory, ask user for feedback first
- ✅ Was branch created before any code changes? → Mandatory, never work on main

### Task-Based Development

When creating or working on tasks from `.github/tasks/`:

1. **Create Feature Branch** - Always create a new branch: `feature/<task-name>`
   ```bash
   git checkout -b feature/task-name
   ```

2. **Task File Format** - All task files MUST follow the [Task Template](./task_template.md):
   - Copy template from `.github/task_template.md`
   - Save to `.github/tasks/<ISSUE_NUMBER>_<snake_case_title>.md`
   - Fill in all sections with YAML frontmatter
   - Required fields: template, agent, status, category, priority, estimated-effort

3. **Branch Naming** - Use descriptive names matching task focus:
   - `feature/<feature-name>` - New features
   - `fix/<bug-description>` - Bug fixes
   - `quality/<improvement-type>` - Code quality improvements
   - `perf/<optimization-area>` - Performance optimizations
   - `ci/<workflow-name>` - CI/CD changes

### Adding Features
See [DMN Feature Template](./prompts/add_dmn_feature.md) for full process. Quick steps:
1. Create feature branch: `git checkout -b feature/<feature-name>`
2. Update headers in `include/orion/bre/`
3. Implement in `src/bre/`
4. Add tests in `tst/bre/`
5. Update `CMakeLists.txt` if needed
6. Validate DMN 1.5 compliance

### Working with Tests
- **Unit Tests**: Boost Test in `tst/bre/`, focus on edge cases
- **TCK Tests**: Official DMN compliance in `dat/dmn-tck/TestCases/`
- **NEVER hardcode test data** - parse from XML test files
- Validate DMN spec compliance, not just implementation

```cpp
// ✅ CORRECT: Parse from official test files
nlohmann::json test_input = parseTestInputFromXML(test_xml_file);

// ❌ WRONG: Hardcoded data
test_input = {{"Monthly Salary", 10000}};
```

### Code Standards
- **Naming**: CamelCase classes, snake_case functions (enforced by clang-tidy)
- **Error Handling**: `ContractViolation` for programming errors, `std::expected` for business logic
- **Memory**: RAII, smart pointers, move semantics
- See [CODING_STANDARDS.md](../CODING_STANDARDS.md) for complete guidelines

## Task Retrospective Process

> ⚠️ **MANDATORY CHECKPOINT**: Do not skip Step 1 - user feedback is required.

After completing tasks from `.github/tasks/`:

1. **ASK for User Feedback** ← **REQUIRED STOP** - "What worked? What was unclear?"
2. **Analyze Execution** - Review conversation for blockers/ambiguities (after user responds)
3. **Document in Task File** - Add to Retrospective section with user feedback + analysis
4. **Update Template** - If patterns emerge across multiple tasks

**Quality Criteria:** Be specific (reference exact issues), actionable (suggest improvements), brief (3-5 bullets max)

## Evidence-Based Reasoning

> ⚠️ **MANDATORY**: Verify before stating facts. No speculation.

**Before making any claim about the codebase:**
- Use `read_file`, `grep_search`, `file_search`, `list_dir` to verify
- Cite specific file paths, line numbers, or command output
- If uncertain, say "I don't have evidence for X" instead of "probably", "likely", "seems"

**Example:**
- ❌ "The code probably uses string_view here"
- ✅ "Checking file... [reads file] ...Line 42 uses `std::string_view name`"

## Command Execution Rules

> ⚠️ **PROHIBITED**: Complex shell operations require manual approval in VS Code.

**WHY:** VS Code AI automation requires simple, verifiable commands.

### ❌ Never Use
- **Pipes**: `command1 | command2` → Use `read_file` + analysis instead
- **Redirection**: `command > file` → Capture output, use file tools if needed
- **Chaining**: `cmd1 && cmd2` → Run separately, verify each step
- **Text Processing**: `awk/sed/grep` in commands → Use VS Code tools

### ✅ Always Use
- **Simple commands**: `cmake --build build`, `clang-tidy src/file.cpp -p build/`, `./build/tst_orion --log_level=test_suite`
- **File tools**: `read_file`, `replace_string_in_file`, `grep_search`, `file_search`
- **Sequential execution**: Run command → verify output → report result → next command

### Quick Reference
| Instead of | Use |
|-----------|-----|
| `cat file.log` | `read_file("file.log")` |
| `grep "error" file` | `grep_search(query="error", includePattern="file")` |
| `find . -name "*.cpp"` | `file_search(query="**/*.cpp")` |
| `cmd \| grep pattern` | Run cmd → analyze output in response |

## Common Workflows

> ⚠️ **IMPORTANT**: Always consult the detailed instruction files for complete workflows:

### Build & Test Workflows

**Before starting any build or test task, READ the applicable instruction file:**
- **Building**: See [Build Instructions](./instructions/build.md) for complete CMake configuration, compiler requirements, and troubleshooting
- **Unit Tests**: See [Unit Test Instructions](./instructions/run_unit_tests.md) for test execution modes, filtering, and debugging
- **TCK Tests**: See [TCK Test Instructions](./instructions/run_tck_tests.md) for compliance testing and regression detection
- **Performance**: See [Performance Test Instructions](./instructions/run_perf_tests.md) for benchmarking and statistical analysis
- **Code Quality**: See [Code Review Checklist](./instructions/code_review_checklist.md) for comprehensive quality gates
- **Clang-Tidy**: See [Clang-Tidy Instructions](./instructions/run_clang_tidy.md) for static analysis and code quality checks
- **Adaptive CI**: See [Adaptive CI Loop](./instructions/adaptive_ci_loop.md) for intelligent testing strategies during code-quality-refactor agent

### Quick Reference (Always verify against instruction files)

**Standard workflow:**
1. Build → Verify build success → Unit tests → Verify tests pass → (Optional) TCK tests
2. Each step must complete successfully before proceeding to the next
3. Never batch or parallelize unless the instruction file explicitly allows it

---

## Available Scripts

**Location:** `tools/scripts/`

**Referenced in documentation:**
- `compare_benchmarks.py` - Statistical benchmark comparison (used in performance workflow)

**Other scripts** (not currently referenced):
- PowerShell: `setup-clang-tidy.ps1`, `run-clang-tidy.ps1`, `autofix.ps1`, `list-project-files.ps1`, `compare_benchmarks.ps1`
- Bash: `orion_bench_smoke.sh`

## Dependencies

**Build System:**
- CMake 3.20+, vcpkg for dependencies
- C++23 standard (fallback to C++20)
- See [build.md](./instructions/build.md) for setup

**Core Libraries:**
- **spdlog** - Logging
- **nlohmann-json** - JSON processing
- **rapidxml** - XML parsing (header-only)
- **boost-test** - Unit testing
- **benchmark** - Performance (optional)

See [CODING_STANDARDS.md](../CODING_STANDARDS.md) for dependency guidelines.